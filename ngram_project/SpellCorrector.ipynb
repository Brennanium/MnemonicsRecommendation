{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python395jvsc74a57bd0dfe826cd0d2d16f756ef7ed973ea241894d65ce5c79e0af9a86738d25b9b6c6c",
   "display_name": "Python 3.9.5 64-bit ('CSCI_404_Final-Yi1LWMfq': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "dfe826cd0d2d16f756ef7ed973ea241894d65ce5c79e0af9a86738d25b9b6c6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import Counter, defaultdict\n",
    "import heapq\n",
    "from operator import itemgetter, attrgetter, methodcaller\n",
    "from nltk.corpus import arcosg"
   ]
  },
  {
   "source": [
    "# Norvig's Spelling Corrector"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "# WORDS = Counter(words(open('big.txt').read()))\n",
    "WORDS = Counter(arcosg.words())\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    # Probability of `word`.\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word,n=5): \n",
    "    # Most probable spelling correction for word.\n",
    "    return heapq.nlargest(n,candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    # Generate possible spelling corrections for word.\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    # The subset of `words` that appear in the dictionary of WORDS.\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    # All edits that are one edit away from `word`.\n",
    "    letters    = \"aàbcdeèfghiìjklmnoòpqrstuùvwxyz'-_\"\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    # All edits that are two edits away from `word`.\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['anns', 'ais', 'a-nis', 'aois', 'nis']"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "correction('anis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['a', 'an', \"a'\", 'am', 'ag']"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "correction('ab')"
   ]
  },
  {
   "source": [
    "## Resources \n",
    "http://norvig.com/spell-correct.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# LinSpell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /// <summary>\n",
    "# /// Computes and returns the Damerau-Levenshtein edit distance between two strings, \n",
    "# /// i.e. the number of insertion, deletion, sustitution, and transposition edits\n",
    "# /// required to transform one string to the other. This value will be >= 0, where 0\n",
    "# /// indicates identical strings. Comparisons are case sensitive, so for example, \n",
    "# /// \"Fred\" and \"fred\" will have a distance of 1. This algorithm is basically the\n",
    "# /// Levenshtein algorithm with a modification that considers transposition of two\n",
    "# /// adjacent characters as a single edit.\n",
    "# /// http://blog.softwx.net/2015/01/optimizing-damerau-levenshtein_15.html\n",
    "# /// https://github.com/softwx/SoftWx.Match\n",
    "# /// </summary>\n",
    "# /// <remarks>See http://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance\n",
    "# /// This is inspired by Sten Hjelmqvist'string1 \"Fast, memory efficient\" algorithm, described\n",
    "# /// at http://www.codeproject.com/Articles/13525/Fast-memory-efficient-Levenshtein-algorithm.\n",
    "# /// This version differs by adding additiona optimizations, and extending it to the Damerau-\n",
    "# /// Levenshtein algorithm.\n",
    "# /// Note that this is the simpler and faster optimal string alignment (aka restricted edit) distance\n",
    "# /// that difers slightly from the classic Damerau-Levenshtein algorithm by imposing the restriction\n",
    "# /// that no substring is edited more than once. So for example, \"CA\" to \"ABC\" has an edit distance\n",
    "# /// of 2 by a complete application of Damerau-Levenshtein, but a distance of 3 by this method that\n",
    "# /// uses the optimal string alignment algorithm. See wikipedia article for more detail on this\n",
    "# /// distinction.\n",
    "# /// </remarks>\n",
    "# /// <license>\n",
    "# /// The MIT License (MIT)\n",
    "# ///\n",
    "# ///Copyright(c) 2015 Steve Hatchett\n",
    "# ///\n",
    "# ///Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# ///of this software and associated documentation files(the \"Software\"), to deal\n",
    "# ///in the Software without restriction, including without limitation the rights\n",
    "# ///to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# ///copies of the Software, and to permit persons to whom the Software is\n",
    "# ///furnished to do so, subject to the following conditions:\n",
    "# ///\n",
    "# ///The above copyright notice and this permission notice shall be included in all\n",
    "# ///copies or substantial portions of the Software.\n",
    "# ///\n",
    "# ///THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# ///IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# ///FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.IN NO EVENT SHALL THE\n",
    "# ///AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# ///LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# ///OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# ///SOFTWARE.\n",
    "# /// </license>\n",
    "\n",
    "\n",
    "# /// <param name=\"string1\">String being compared for distance.</param>\n",
    "# /// <param name=\"string2\">String being compared against other string.</param>\n",
    "# /// <param name=\"maxDistance\">The maximum edit distance of interest.</param>\n",
    "# /// <returns>int edit distance, >= 0 representing the number of edits required\n",
    "# /// to transform one string to the other, or -1 if the distance is greater than the specified maxDistance.</returns>\n",
    "def DamerauLevenshteinDistance(string1, string2, maxDistance):\n",
    "    if string1 is None or len(string1) == 0: return 0 if string2 is None else len(string2)\n",
    "    if string2 is None or len(string2) == 0: return len(string1)\n",
    "\n",
    "    # if strings of different lengths, ensure shorter string is in string1. This can result in a little\n",
    "    # faster speed by spending more time spinning just the inner loop during the main processing.\n",
    "    # swap string1 and string2\n",
    "    if len(string1) > len(string2):\n",
    "        temp = string1\n",
    "        string1 = string2\n",
    "        string2 = temp \n",
    "\n",
    "    sLen = len(string1) # this is also the minimun length of the two strings\n",
    "    tLen = len(string2)\n",
    "\n",
    "    #  suffix common to both strings can be ignored\n",
    "    while ((sLen > 0) and (string1[sLen - 1] == string2[tLen - 1])): \n",
    "        sLen -= 1 \n",
    "        tLen -= 1\n",
    "\n",
    "    start = 0\n",
    "    if ((string1[0] == string2[0]) or (sLen == 0)): # if there'string1 a shared prefix, or all string1 matches string2'string1 suffix\n",
    "                                                    # prefix common to both strings can be ignored\n",
    "        while ((start < sLen) and (string1[start] == string2[start])): start += 1\n",
    "\n",
    "        sLen -= start # length of the part excluding common prefix and suffix\n",
    "        tLen -= start\n",
    "\n",
    "        # if all of shorter string matches prefix and/or suffix of longer string, then\n",
    "        # edit distance is just the delete of additional characters present in longer string\n",
    "        if (sLen == 0): return tLen\n",
    "\n",
    "        string2 = string2[start:(start+tLen)] # faster than string2[start+j] in inner loop below\n",
    "    \n",
    "    lenDiff = tLen - sLen\n",
    "    if ((maxDistance < 0) or (maxDistance > tLen)):\n",
    "        maxDistance = tLen\n",
    "    elif (lenDiff > maxDistance): return -1\n",
    "\n",
    "    v0 = [0 for i in range(tLen)]\n",
    "    v2 = [0 for i in range(tLen)]  # stores one level further back (offset by +1 position)\n",
    "    j = 0\n",
    "    while j < maxDistance: \n",
    "        v0[j] = j + 1\n",
    "        # v0.append(j + 1)\n",
    "        j += 1\n",
    "    while j < tLen: \n",
    "        v0[j] = maxDistance + 1\n",
    "        # v0.append(maxDistance + 1)\n",
    "        j += 1\n",
    "    \n",
    "    jStartOffset = maxDistance - (tLen - sLen)\n",
    "    haveMax = maxDistance < tLen\n",
    "    jStart = 0\n",
    "    jEnd = maxDistance\n",
    "    sChar = string1[0]\n",
    "    current = 0\n",
    "    for i in range(0, sLen):\n",
    "        prevsChar = sChar\n",
    "        sChar = string1[start + i]\n",
    "        tChar = string2[0]\n",
    "        left = i\n",
    "        current = left + 1\n",
    "        nextTransCost = 0\n",
    "        # no need to look beyond window of lower right diagonal - maxDistance cells (lower right diag is i - lenDiff)\n",
    "        # and the upper left diagonal + maxDistance cells (upper left is i)\n",
    "        jStart += int(i > jStartOffset)\n",
    "        jEnd += int(jEnd < tLen)\n",
    "        j = jStart\n",
    "        while j < jEnd:\n",
    "            above = current\n",
    "            thisTransCost = nextTransCost\n",
    "            nextTransCost = v2[j]\n",
    "            v2[j] = current = left  # cost of diagonal (substitution)\n",
    "            left = v0[j]            # left now equals current cost (which will be diagonal at next iteration)\n",
    "            prevtChar = tChar\n",
    "            tChar = string2[j]\n",
    "            if (sChar != tChar):\n",
    "                if (left < current): current = left     # insertion\n",
    "                if (above < current): current = above   # deletion\n",
    "                current += 1\n",
    "                if ((i != 0) and (j != 0) and (sChar == prevtChar) and (prevsChar == tChar)):\n",
    "                    thisTransCost += 1\n",
    "                    if (thisTransCost < current): current = thisTransCost    # transposition\n",
    "            v0[j] = current\n",
    "            j += 1\n",
    "        if (haveMax and (v0[i + lenDiff] > maxDistance)): return -1\n",
    "    return current if (current <= maxDistance) else -1"
   ]
  },
  {
   "source": [
    "editDistanceMax=2\n",
    "\n",
    "\n",
    "# public class SuggestItem\n",
    "# {\n",
    "#     public string term = \"\";\n",
    "#     public int distance = 0;\n",
    "#     public Int64 count = 0;\n",
    "\n",
    "#     public override bool Equals(object obj)\n",
    "#     {\n",
    "#         return Equals(term, ((SuggestItem)obj).term);\n",
    "#     }\n",
    "    \n",
    "#     public override int GetHashCode()\n",
    "#     {\n",
    "#         return term.GetHashCode();\n",
    "#     }\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "unigrams = [ug for sent in arcosg.sents() for ug in sent]\n",
    "# unigram_fdist = nltk.FreqDist(unigrams)\n",
    "\n",
    "# dictionaryLinear = {}\n",
    "dictionaryLinear = nltk.FreqDist(unigrams)\n",
    "# dictionaryLinear = WORDS\n",
    "maxlength = 0; # maximum dictionary term length\n",
    "\n",
    "# verbose = 0\n",
    "# 0: top suggestion\n",
    "# 1: all suggestions of smallest edit distance   \n",
    "# 2: all suggestions <= editDistanceMax (slower, no early termination)\n",
    "def LookupLinear(input, editDistanceMax, verbose=0):\n",
    "    suggestions = []\n",
    "\n",
    "    editDistanceMax2 = editDistanceMax\n",
    "\n",
    "    if verbose < 2 and (count := dictionaryLinear[input]) > 0:\n",
    "        return (input, count, 0)\n",
    "\n",
    "    for key, value in dictionaryLinear.items():\n",
    "        if abs(len(key) - len(input)) > editDistanceMax2: continue\n",
    "\n",
    "        # if already ed1 suggestion, there can be no better suggestion with smaller count: no need to calculate damlev\n",
    "        if ((verbose == 0) and (len(suggestions) > 0) and (suggestions[0][2] == 1) and (value <= suggestions[0][1])):  continue\n",
    "\n",
    "        distance = DamerauLevenshteinDistance(input, key, editDistanceMax2); \n",
    "        # sometimes DamerauLevenshteinDistance returnes a distance > editDistanceMax\n",
    "        if ((distance >= 0) and (distance <= editDistanceMax)):\n",
    "            # v0: clear if better ed or better ed+count; \n",
    "            # v1: clear if better ed                    \n",
    "            # v2: all\n",
    "\n",
    "            # do not process higher distances than those already found, if verbose<2\n",
    "            if ((verbose < 2) and (len(suggestions) > 0) and (distance > suggestions[0][2])): continue\n",
    "\n",
    "            # we will calculate DamLev distance only to the smallest found distance sof far\n",
    "            if (verbose < 2): editDistanceMax2 = distance\n",
    "\n",
    "            # remove all existing suggestions of higher distance, if verbose<2\n",
    "            if ((verbose < 2) and (len(suggestions) > 0) and (suggestions[0][2] > distance)): suggestions = []\n",
    "\n",
    "            suggestions.append((key, value, distance))\n",
    "    \n",
    "\n",
    "    if (verbose < 2): \n",
    "        # sort by descending word frequency\n",
    "        suggestions.sort(key=lambda x: -x[1]) \n",
    "    else: \n",
    "        # sort by ascending edit distance, then by descending word frequency\n",
    "        # suggestions.Sort((x, y) => 2 * x.distance.CompareTo(y.distance) - x.count.CompareTo(y.count));\n",
    "        suggestions.sort(key=lambda x: (x[2], -x[1]))\n",
    "    \n",
    "    if ((verbose == 0) and (len(suggestions) > 1)):\n",
    "        return suggestions[0:1]\n",
    "    else: \n",
    "        return suggestions\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('anns', 198, 1),\n",
       " ('ais', 141, 1),\n",
       " ('a-nis', 40, 1),\n",
       " ('aois', 23, 1),\n",
       " ('Inis', 7, 1),\n",
       " ('nis', 6, 1),\n",
       " ('a_nis', 1, 1)]"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "LookupLinear(\"anis\",2,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('ràinig', 28, 4), ('Nirribhidh', 7, 4), ('Nèibhi', 1, 4)]"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "LookupLinear(\"Nrrihbig\",4,verbose=1)"
   ]
  },
  {
   "source": [
    "## Resources\n",
    "https://github.com/wolfgarbe/LinSpell/blob/master/linspell/LinSpell.cs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cat\ncar\n"
     ]
    }
   ],
   "source": [
    "import pygtrie\n",
    "\n",
    "\n",
    "t = pygtrie.PrefixSet(iterable=['cat','caterpillar','car','bar','exit','cats'],factory=pygtrie.CharTrie)\n",
    "# t['cat'] = True\n",
    "# t['caterpillar'] = True\n",
    "# t['car'] = True\n",
    "# t['bar'] = True\n",
    "# t['exit'] = False\n",
    "\n",
    "for s in t.iter(prefix='ca'):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "87040\nTrue\n"
     ]
    }
   ],
   "source": [
    "from lexpy.trie import Trie\n",
    "\n",
    "trie = Trie()\n",
    "\n",
    "trie.add_all([w for w in arcosg.words()])\n",
    "\n",
    "print(trie.get_word_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('an-dràst', 2), ('an-dràsta', 17), ('an-dràsd', 1), ('an-dràsda', 24)]\n[('an-dràst', 2), ('an-dràsta', 17), ('an-dràsd', 1), ('an-dràsda', 24), ('an_dràsda', 9), ('an_dràsta', 2)]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}